After all, even though today's artificial intelligence can beat humans within narrow domains (such as chess or trivia games), machine brains are still extremely rudimentary in general intelligence.
But this could change.
By 2050 we may, according to a recent survey of leading artificial intelligence researchers, have a 50/50 chance of achieving human-level machine intelligence (defined here as "one that can carry out most human professions at least as well as a typical human").
The next stop from human level intelligence, just a short distance farther along the tracks, is machine superintelligence.
In "Superintelligence: Paths, Dangers, Strategies," I focus on the dynamics of an intelligence explosion; what will happen if and when we gain the ability to create machine superintelligence?
A superintelligence wouldn't even need to start with a physical embodiment to be catastrophically dangerous.
An unfriendly superintelligence would not permit a mulligan.
that is safe, beneficial and ethical, but we don't know exactly what that entails.
In this sense, we have philosophy with a deadline.